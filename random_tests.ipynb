{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os \n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils import config\n",
    "from utils import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "            dbname=config.DATABASE['DBNAME'],\n",
    "            host=config.DATABASE['HOST'],\n",
    "            user=config.DATABASE['USER'],\n",
    "            password=config.DATABASE['PASSWORD'],\n",
    "            port=config.DATABASE['PORT'],\n",
    "        )\n",
    "\n",
    "engine = create_engine(\n",
    "            f\"postgresql://{config.DATABASE['USER']}:\"\n",
    "            f\"{config.DATABASE['PASSWORD']}@\"\n",
    "            f\"{config.DATABASE['HOST']}:\"\n",
    "            f\"{config.DATABASE['PORT']}/\"\n",
    "            f\"{config.DATABASE['DBNAME']}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nall_ids = []\\nwith gzip.open(config.TWEETS_PATH, 'rb') as f:\\n    for row_number, current_tweet in enumerate(f):\\n        all_ids.append(json.loads(current_tweet.decode(encoding='utf-8'))['id'])\\n\\nprint(f'Unique id amount: {len(set(all_ids))}, out of total id amount: {len(all_ids)}')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "all_ids = []\n",
    "with gzip.open(config.TWEETS_PATH, 'rb') as f:\n",
    "    for row_number, current_tweet in enumerate(f):\n",
    "        all_ids.append(json.loads(current_tweet.decode(encoding='utf-8'))['id'])\n",
    "\n",
    "print(f'Unique id amount: {len(set(all_ids))}, out of total id amount: {len(all_ids)}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xschon/Desktop/PDT/Z1/utils/utilities.py:39: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, con=conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100000\n",
    "\n",
    "data_rows = []\n",
    "conversations_existing_ids = utilities.run_written_query('SELECT id FROM conversations', to_dataframe=True, option='from_string').id.astype(str).values\n",
    "with gzip.open(config.TWEETS_PATH, 'rb') as f:\n",
    "    for row_number, current_tweet in enumerate(f):\n",
    "        data_rows.append(json.loads(current_tweet.decode(encoding='utf-8')))\n",
    "        if (row_number+1) % batch_size == 0:\n",
    "            print(row_number+1)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author_id', 'conversation_id', 'created_at', 'entities', 'id',\n",
       "       'language', 'possibly_sensitive', 'public_metrics', 'referenced_tweets',\n",
       "       'reply_settings', 'source', 'content', 'context_annotations',\n",
       "       'attachments', 'in_reply_to_user_id', 'geo', 'withheld', 'like_count',\n",
       "       'quote_count', 'reply_count', 'retweet_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.DataFrame(data_rows)\n",
    "metrics = pd.DataFrame(tweets.public_metrics.to_list())\n",
    "tweets[metrics.columns] = metrics\n",
    "tweets.rename(columns={'text' : 'content',\n",
    "                       'lang' : 'language',\n",
    "\n",
    "                    }, inplace=True)\n",
    "\n",
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO authors uploading when uploading conversations_table\n",
    "# TODO drop duplicates of ids\n",
    "\n",
    "conversations_table = tweets[['id', 'author_id', 'content', 'possibly_sensitive', 'language',\n",
    "        'source', 'retweet_count', 'reply_count', 'like_count', 'quote_count', 'created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74074\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# Find all referenced tweets - iterate over existing array of references for each tweet\n",
    "refs = tweets.dropna(subset='referenced_tweets')[['id', 'referenced_tweets']]\n",
    "conversation_references_table = pd.DataFrame(columns=['conversation_id', 'parent_id', 'type'])\n",
    "\n",
    "for layer in range(refs.referenced_tweets.apply(lambda x : len(x)).max()):\n",
    "    # Select all references from given layer and find tweets they reffer to\n",
    "    layer_references = refs.referenced_tweets.apply(lambda x : x[layer] if(len(x) > layer) else None).dropna()\n",
    "    conv_refs = pd.DataFrame(layer_references.to_list(), index=layer_references.index)\n",
    "    conv_refs.rename(columns={'id' : 'parent_id'}, inplace=True)\n",
    "    conv_refs = (conv_refs.join(refs.id).rename(columns={'id' : 'conversation_id'}))\n",
    "\n",
    "    conversation_references_table = pd.concat([conversation_references_table, conv_refs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_table = pd.DataFrame(columns=['conversation_id', 'url', 'title', 'description'])\n",
    "links_raw = pd.DataFrame(tweets.dropna(subset='entities').entities.to_list()).dropna(subset='urls').urls\n",
    "\n",
    "\n",
    "for layer in range(links_raw.apply(lambda x : len(x)).max()):\n",
    "    layer_links = links_raw.apply(lambda x : x[layer] if (len(x) > layer) else None).dropna()\n",
    "    tmp_links = pd.DataFrame(layer_links.to_list(), index=layer_links.index)\n",
    "    tmp_links = tmp_links.join(tweets.id).rename(columns={'id' : 'conversation_id'})\n",
    "\n",
    "    links_table = pd.concat([links_table, tmp_links])[list(links_table.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id     object\n",
       "value               object\n",
       "type                object\n",
       "probability        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_table.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>probability</th>\n",
       "      <th>start</th>\n",
       "      <th>type</th>\n",
       "      <th>conversation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>14</td>\n",
       "      <td>Person</td>\n",
       "      <td>1496732916281491458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>CHABELO</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>66</td>\n",
       "      <td>Person</td>\n",
       "      <td>1496732914503069698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>0.8356</td>\n",
       "      <td>23</td>\n",
       "      <td>Place</td>\n",
       "      <td>1496732916784582659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>48</td>\n",
       "      <td>Latinoamérica</td>\n",
       "      <td>0.8778</td>\n",
       "      <td>36</td>\n",
       "      <td>Place</td>\n",
       "      <td>1496732918009548804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>38</td>\n",
       "      <td>Place</td>\n",
       "      <td>1496732920286875649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99500</th>\n",
       "      <td>36</td>\n",
       "      <td>Biden</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>32</td>\n",
       "      <td>Person</td>\n",
       "      <td>1496765509638889472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99505</th>\n",
       "      <td>42</td>\n",
       "      <td></td>\n",
       "      <td>0.4662</td>\n",
       "      <td>42</td>\n",
       "      <td>Person</td>\n",
       "      <td>1496765508150046728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99513</th>\n",
       "      <td>57</td>\n",
       "      <td>Nobel Peace Prize</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>41</td>\n",
       "      <td>Other</td>\n",
       "      <td>1496765511257968642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99514</th>\n",
       "      <td>121</td>\n",
       "      <td>Tercera Guerra Mundial</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>100</td>\n",
       "      <td>Other</td>\n",
       "      <td>1496765510913957890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99521</th>\n",
       "      <td>89</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>83</td>\n",
       "      <td>Place</td>\n",
       "      <td>1496765513430671360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       end         normalized_text  probability  start    type  \\\n",
       "2       22               Joe Biden       0.9976     14  Person   \n",
       "3       72                 CHABELO       0.5075     66  Person   \n",
       "5       29                 Ukraine       0.8356     23   Place   \n",
       "13      48           Latinoamérica       0.8778     36   Place   \n",
       "14      44                 Ukraine       0.8824     38   Place   \n",
       "...    ...                     ...          ...    ...     ...   \n",
       "99500   36                   Biden       0.9821     32  Person   \n",
       "99505   42                               0.4662     42  Person   \n",
       "99513   57       Nobel Peace Prize       0.3290     41   Other   \n",
       "99514  121  Tercera Guerra Mundial       0.8203    100   Other   \n",
       "99521   89                 Ukraine       0.9125     83   Place   \n",
       "\n",
       "           conversation_id  \n",
       "2      1496732916281491458  \n",
       "3      1496732914503069698  \n",
       "5      1496732916784582659  \n",
       "13     1496732918009548804  \n",
       "14     1496732920286875649  \n",
       "...                    ...  \n",
       "99500  1496765509638889472  \n",
       "99505  1496765508150046728  \n",
       "99513  1496765511257968642  \n",
       "99514  1496765510913957890  \n",
       "99521  1496765513430671360  \n",
       "\n",
       "[24678 rows x 6 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_table = pd.DataFrame(columns=['conversation_id', 'value', 'type', 'probability'])\n",
    "annotations_raw = links_raw = pd.DataFrame(tweets.dropna(subset='entities').entities.to_list()).dropna(subset='annotations').annotations\n",
    "\n",
    "for layer in range(annotations_raw.apply(lambda x : len(x)).max()):\n",
    "    layer_annotations = annotations_raw.apply(lambda x : x[layer] if (len(x)>layer) else None).dropna()\n",
    "    tmp_annotations  = pd.DataFrame(layer_annotations.to_list(), index=layer_annotations.index)\n",
    "    tmp_annotations.rename(columns={'normalized_text' : 'values'}, inplace=True)\n",
    "    tmp_annotations = tmp_annotations.join(tweets.id).rename(columns={'id' : 'conversation_id'})\n",
    "    \n",
    "    annotations_table = pd.concat([annotations_table, tmp_annotations])[list(annotations_table.columns)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
